# Fraud Detection Pipeline â€“ AWS + Terraform

This repository contains a Proofâ€‘ofâ€‘Concept (PoC) **AIâ€‘enabled fraud detection pipeline** deployed on AWS using **Terraform**.  
The solution demonstrates an endâ€‘toâ€‘end machine learning workflow for **credit card fraud detection**, using a synthetic dataset sourced from Kaggle.

---

## ğŸ“Œ Overview

The pipeline automates ingestion, transformation, model training, inference, and analytics.  
The design is derived from the accompanying architecture slide deck, showing a modular cloudâ€‘native ML flow using AWS services. 


he pipeline automates ingestion, transformation, model training, inference, and analytics.  
The design is derived from the accompanying architecture slide deck, showing a modular cloudâ€‘native ML flow using AWS services.

### Highâ€‘Level Workflow
- Raw data ingestion into **S3 Landing Bucket**
- Data cleaning & transformation with **Glue Jobs**
- Fraud detection & prediction using a **SageMaker AI model**
- Processed output organised into **train**, **validation**, **model**, and **prediction** folders in S3
- Analytics & dashboards generated in **QuickSight**
- Workflow automation via **AWS Step Functions**
- Monitoring with **CloudWatch**
- SQLâ€‘style interrogation using **Athena**

---

## ğŸš€ Architecture Overview

### Core AWS Components

#### **S3 Landing Bucket**
Stores raw credit card transaction data before processing.  
Derived from the ingestion stage of the pipeline.

#### **AWS Glue Jobs**
Performs ETL including:  
- Data cleaning  
- Data standardisation  
- Transformation to modelâ€‘ready format  
Based on the â€œData Cleaning & Transformationâ€ stage.

#### **S3 Processed Buckets**
Output folder structure:

#### **SageMaker Training & Inference**
Supports:  
- Model training  
- Deployment  
- Fraud prediction checks  
Matches the â€œAI Base Fraud Detection & Predictionâ€ and deployment steps.

#### **AWS Step Functions**
Orchestrates automated flow:  
Ingest â†’ Transform â†’ Train â†’ Deploy â†’ Predict  
Shown as â€œOrchestrate Workflow for Automationâ€.

#### **CloudWatch**
Monitors system health and logs pipeline execution.  
Matches the â€œMonitor Pipeline Healthâ€ component.

#### **Athena & QuickSight**
- Athena provides SQLâ€‘based querying over processed data.  
- QuickSight visualises fraud insights on dashboards.  
These cover â€œDisplays analysis on a Dashboardâ€ and â€œAthenaâ€ items.

---

## ğŸ§  Machine Learning Elements

The solution uses **synthetic Kaggle credit card transaction data** for fraud detection experiments.

### Workflow
- Data is cleaned through Glue  
- Training & validation sets generated  
- Model training performed in SageMaker  
- Predictions written to S3 under `predictions/`  
- Dashboard visuals updated in QuickSight  

This reflects the SageMaker training and prediction flow in the slide deck.

---

## ğŸ“¦ Infrastructure as Code (Terraform)

Terraform is used to provision the entire stack, including:
- S3 buckets  
- Glue ETL jobs  
- IAM policies and roles  
- SageMaker training and inference resources  
- Step Functions workflow definition  
- CloudWatch alarms & log groups  
- Athena database/table definitions  
- QuickSight assets where supported  

This enables reproducibility and provides a template for future AWSâ€‘based AI pipelines.


## â–¶ï¸ Getting Started

### Prerequisites
- Terraform CLI  
- AWS credentials configured  
- Kaggle dataset placed in `/data` or uploaded to S3

### Deploy Infrastructure
```bash
cd terraform/environments/dev
terraform init
terraform apply
```

## Run the Pipeline

- Upload dataset to the Landing S3 bucket.
- Step Functions triggers ETL, training, and predictions.
- Trained model is deployed in SageMaker.
- Predictions are stored in S3.
- Dashboard updates in QuickSight.

## Dashboards & Analytics
QuickSight provides:

- Fraud probability heatmaps
- Highâ€‘risk transaction summaries
- Timeâ€‘series anomaly visualisation
- Model performance graphs

Athena allows flexible adâ€‘hoc interrogation of model outputs and processed datasets.

## Extending the Template
This pattern can be reused across:

- Fraud detection workloads
- Anomaly and risk scoring systems
- Automated ML pipelines on AWS
- Data engineering & ETL orchestrated workflows
